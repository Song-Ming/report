\chapter{Evaluation}
\label{chap:Evaluation}

\section{Results}
\label{sec:Results}

% \begin{flushleft}
% Training and evaluation were both performed with an RTX6000 GPU    
% \end{flushleft}

\subsection{Evaluation Metrics}
\label{imp:sec:Evaluation Metrics}

\begin{flushleft}
The models were evaluated using accuracy, precision, recall, F1 score and AUROC (for the CNN models only).
The first 4 metrics are calculated based on the true positive (TP), true negative (TN), false positive (FP) and
false negative (FN) values at a particular prediciton threshold. AUROC is calculated from a plot of the sensitivity (recall) 
of a model against specificity at different prediction thresholds. The equations are as follows:

\begin{equation}
Accuracy=\frac{TP+TN}{TP+TN+FP+FN}
\end{equation}

\begin{equation}
Precision=\frac{TP}{TP+FP}
\end{equation}

\begin{equation}
Recall=\frac{TP}{TP+FN}
\end{equation}

\begin{equation}
F\textit{1}\,score=\frac{2*TP}{2*TP+FP+FN}
\end{equation}

\begin{equation}
Specificity=\frac{TN}{TN+FP}
\end{equation}

\end{flushleft}

\pagebreak
\subsection{Results}
\label{imp:sec:Results}

\begin{flushleft}
The 4 CNN models were evaluated at a balanced threshold of 0.5 for all metrics except AUROC. Convnext achieved 
an accuracy of 93.4\%, precision of 92.7\%, recall of 92.2\%, F1 score of 92.5\% and AUROC of 0.976. EfficientNet 
achieved an accuracy of 90.1\%, precision of 90.3\%, recall of 87.0\%, F1 score of 88.7\% and AUROC of 0.971.
MobileNet achieved an accuracy of 90.6\%, precision of 86.5\%, recall of 93.2\%, F1 score of 89.8\% and AUROC of 0.953.
The Ensemble model achieved an accuracy of 93.8\%, precision of 91.9\%, recall of 94.3\%, F1 score of 93.1\% and AUROC
of 0.978.

\begin{table}[h!] % [h!] suggests placing the table "here" if possible
    \centering % Centers the table on the page
    \begin{tabular}{|c|c|c|c|c|c|} % Defines column types and vertical lines
        \hline % Horizontal line at the top
        Model & Accuracy & Precision & Recall & F1 score & AUC-ROC \\ % Table headers
        \hline % Horizontal line below headers
        ConvNeXt & 0.934 & 0.927 & 0.922 & 0.925 & 0.976 \\
        \hline % Horizontal line between rows
        EfficientNet & 0.901 & 0.903 & 0.870 & 0.887 & 0.971 \\
        \hline % Horizontal line between rows
        MobileNet & 0.906 & 0.865 & 0.932 & 0.898 & 0.953 \\
        \hline % Horizontal line between rows
        Ensemble & 0.938 & 0.919 & 0.943 & 0.931 & 0.978 \\
        \hline % Horizontal line at the bottom
    \end{tabular}
    \caption{CNN results} % Table caption
    \label{tab:CNN results} % Label for referencing the table
\end{table}

Without pretraining or any changes to the architecture from the publicly available version, Convnext achieved 
an accuracy of 90.6\%, precision of 87.3\%, recall of 92.2\%, F1 score of 89.7\% and AUROC of 0.945. EfficientNet 
achieved an accuracy of 87.0\%, precision of 83.7\%, recall of 87.6\%, F1 score of 85.6\% and AUROC of 0.941.
MobileNet achieved an accuracy of 89.2\%, precision of 86.1\%, recall of 90.2\%, F1 score of 88.1\% and AUROC of 0.935.

\begin{table}[h!] % [h!] suggests placing the table "here" if possible
    \centering % Centers the table on the page
    \begin{tabular}{|c|c|c|c|c|c|} % Defines column types and vertical lines
        \hline % Horizontal line at the top
        Model & Accuracy & Precision & Recall & F1 score & AUC-ROC \\ % Table headers
        \hline % Horizontal line below headers
        ConvNeXt & 0.906 & 0.873 & 0.922 & 0.897 & 0.945 \\
        \hline % Horizontal line between rows
        EfficientNet & 0.870 & 0.837 & 0.876 & 0.856 & 0.941 \\
        \hline % Horizontal line between rows
        MobileNet & 0.892 & 0.861 & 0.902 & 0.881 & 0.935 \\
        \hline % Horizontal line at the bottom
    \end{tabular}
    \caption{CNN results Without pretraining} % Table caption
    \label{tab:CNN results Without pretraining} % Label for referencing the table
\end{table}

For MedGemma and LLaVA-Rad, the predictions are obtained from the generated text output and does not have a 
threshold like the CNN models. Hence, AUC-ROC could not be calculated. MedGemma achieved an accuracy of 88.1\%,
precision of 86.2\%, recall of 87.0\% and F1 score of 86.6\%. LLaVA-Rad achieved an accuracy of 91.5\%, precision of
87.9\%, recall of 93.8\% and F1 score of 90.7\%.

\begin{table}[h!] % [h!] suggests placing the table "here" if possible
    \centering % Centers the table on the page
    \begin{tabular}{|c|c|c|c|c|c|} % Defines column types and vertical lines
        \hline % Horizontal line at the top
        Model & Accuracy & Precision & Recall & F1 score & AUC-ROC \\ % Table headers
        \hline % Horizontal line below headers
        MedGemma & 0.881 & 0.862 & 0.870 & 0.866 & - \\
        \hline % Horizontal line between rows
        LLaVA-Rad & 0.915 & 0.879 & 0.938 & 0.907 & -\\
        \hline % Horizontal line at the bottom
    \end{tabular}
    \caption{VLM results} % Table caption
    \label{tab:VLM results} % Label for referencing the table
\end{table}

\pagebreak
\begin{figure}[ht] % [h!] suggests "here" but allows LaTeX to adjust placement
    \centering % Centers the entire figure environment

    \begin{subfigure}[b]{0.45\textwidth} % [b] for bottom alignment, width is 45% of text width
        \includegraphics[width=\textwidth]{Convnext.png} % image1.png will fill the subfigure width
        \caption{Convnext}
        \label{fig:matrix1}
    \end{subfigure}
    \hfill % Horizontal fill to create space between subfigures
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{EfficientNet.png}
        \caption{EfficientNet}
        \label{fig:matrix2}
    \end{subfigure}

    \vspace{1em} % Vertical space between rows

    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{MobileNet.png}
        \caption{MobileNet}
        \label{fig:matrix3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{Ensemble.png}
        \caption{Ensemble}
        \label{fig:matrix4}
    \end{subfigure}

    \caption{Confusion matrices for CNN models}
    \label{fig:Confusion matrices for CNN models}
\end{figure}

\pagebreak
\begin{figure}[ht] % [h!] suggests "here" but allows LaTeX to adjust placement
    \centering % Centers the entire figure environment

    \begin{subfigure}[b]{0.45\textwidth} % [b] for bottom alignment, width is 45% of text width
        \includegraphics[width=\textwidth]{Convnext base.png} % image1.png will fill the subfigure width
        \caption{Convnext}
        \label{fig:matrix5}
    \end{subfigure}
    \hfill % Horizontal fill to create space between subfigures
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{EfficientNet base.png}
        \caption{EfficientNet}
        \label{fig:matrix6}
    \end{subfigure}

    \vspace{1em} % Vertical space between rows

    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{MobileNet base.png}
        \caption{MobileNet}
        \label{fig:matrix7}
    \end{subfigure}
    \hfill
    % \begin{subfigure}[b]{0.45\textwidth}
    %     \includegraphics[width=\textwidth]{Ensemble.png}
    %     \caption{Ensemble}
    %     \label{fig:image4}
    % \end{subfigure}

    \caption{Confusion matrices for CNN models without pretraining}
    \label{fig:Confusion matrices for CNN models without pretraining}
\end{figure}

\pagebreak
\begin{figure}[ht] % [h!] suggests "here" but allows LaTeX to adjust placement
    \centering % Centers the entire figure environment

    \begin{subfigure}[b]{0.45\textwidth} % [b] for bottom alignment, width is 45% of text width
        \includegraphics[width=\textwidth]{MedGemma.png} % image1.png will fill the subfigure width
        \caption{Medgemma}
        \label{fig:matrix8}
    \end{subfigure}
    \hfill % Horizontal fill to create space between subfigures
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{LLaVA-Rad.png}
        \caption{LLaVA-Rad}
        \label{fig:matrix9}
    \end{subfigure}

    \caption{Confusion matrices for VLM models}
    \label{fig:Confusion matrices for VLM models}
\end{figure}
\end{flushleft}

\pagebreak
\section{Discussion}
\label{sec:Discussion}

\begin{flushleft}
From the results, the combination of pretraining on a related dataset and the changes made to the architectures of the CNN models
had a significant impact on performance. Convnext had a 2.8\% increase in accuracy and 0.031 increase in AUROC, EfficientNet had a 3.1\%
increase in accuracy and 0.03 increase in AUROC, MobileNet had a 1.4\% increase in accuracy and 0.018 increase in AUROC. This indicates that
pretraining on the MURA dataset helped to reduce the mismatch issue between ImageNet and the target dataset. The addition of convolutional
block attention modules also improved the ability of the models to focus on relevant parts of the image thus improving performance. The improvement
was larger for Convnext and EfficientNet than MobileNet which may be due to the larger size of the first 2 models. 

The ensemble model had a 0.4\% increase in accuracy and 0.002 increase in AUROC compared to Convnext which is the best performing individual model. 
This is a relatively small difference in performance. However, the ensemble model had a higher recall than all 3 of the individual models with 2.1\% 
higher recall than Convnext, 7.3\% higher recall than EfficientNet and 1.1\% higher recall than MobileNet. The model also had a higher precision than
EfficientNet and MobileNet although it had a 0.8\% lower precision than Convnext.

In Alzubaidi et al., pretraining yielded improvements of between 2\% and 9\% accuracy over using just ImageNet which is much larger than the
improvement seen here. This may be because of differences in the target dataset. In Alzubaidi et al, the target dataset was the subset of humerus X-rays
in MURA which comes from the same source as the rest of the dataset. In contrast, the elbow X-rays used here come from a different source and have different 
characteristics from the X-rays in the MURA dataset which reduces the impact of the pretraining step. In Alzubaidi et al. and Tahir et al., the ensemble model 
showed an improvement of over 20\% and 2\% accuracy respectively over the best performing individual model. This is much larger than the improvement seen in our 
ensemble model. The small improvement suggests that the features collected from the 3 individual models may be too similar to each other resulting in a smaller benefit 
from the feature fusion.

For the VLM models, MedGemma generally had a worse performance than any of the individual CNN models, only beating EfficientNet without pretraining. 
In contrast, LLaVA-Rad had a better accuracy and F1 score than EfficientNet and MobileNet, only losing to ConvNeXt and the Ensemble model. In addition, 
LLaVA-Rad had the second highest recall out of all the models. In the case of automated fracture detection, the cost of a false negative is 
significantly higher than the cost of a false positive. 

As mentioned in the introduction, an undiagnosed elbow fracture could lead to further complications for a patient whereas a false diagnosis wastes 
the time of the radiologist which is a less serious problem. Hence, a high recall is arguably more important than a high precision. From this 
standpoint, the Ensemble was the best model followed by LLaVA-Rad. In addition because of the computational requirements, the VLMs were not 
pretrained on the MURA dataset which might have increased their performance significantly. Hence, although the performance of the VLMs are not the 
best, LLaVA-Rad in particular shows potential for further development.
\end{flushleft}

\section{Future Work}
\label{sec:Future Work}

\begin{flushleft}
placeholder
- Continue to work with VLMs
- Collect more data from local sources for pretraining instead of mura
- Try different ensemble techniques, use larger number of smaller models
- Try using gradcam and LVLM-Interpret for visualisation
\end{flushleft}

